{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Palpax Online Assessment.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNHOAa19A68VzD9nHoBh9E+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ASHwaniC/Machine-Learning-Algorithm-Codes/blob/main/SVM%20Linear.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0klMQ0DIS7tp"
      },
      "source": [
        "SVM(Linear)\n",
        "\n",
        "In machine learning, support-vector machines (SVMs, also support-vector networks) are supervised learning models with associated learning algorithms that analyze data used for classification and regression analysis. Given a set of training examples, each marked as belonging to one or the other of two categories, an SVM training algorithm builds a model that assigns new examples to one category or the other, making it a non-probabilistic binary linear classifier (although methods such as Platt scaling exist to use SVM in a probabilistic classification setting). An SVM model is a representation of the examples as points in space, mapped so that the examples of the separate categories are divided by a clear gap that is as wide as possible. New examples are then mapped into that same space and predicted to belong to a category based on the side of the gap on which they fall."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUvEICt8Jznx"
      },
      "source": [
        "class SVM:\n",
        "  def __init__(self, learning_rate = 0.001, lambda_param=0.01, n_iters=1000):\n",
        "    self.lr = learning_rate\n",
        "    self.lambda_param = lambda_param\n",
        "    self.n_iters = n_iters\n",
        "    self.w = None\n",
        "    self.b = None\n",
        "\n",
        "  def fit(self, X, y):\n",
        "    y_ = np.where(y<=0,-1,1)\n",
        "    n_samples, n_features = X.shape\n",
        "\n",
        "    self.w = np.zeros(n_features)\n",
        "    self.b = 0\n",
        "\n",
        "    for _ in range(self.n_iters):\n",
        "      for idx, x_i in enumerate(X):\n",
        "        condition = y_[idx] * (np.dot(x_i, self.w) - self.b) >=1\n",
        "        if condition:\n",
        "          self.w -= self.lr * (2*self.lambda_param * self.w)\n",
        "        else:\n",
        "          self.w -= self.lr * (2 * self.lambda_param * self.w - np.dot(x_i, y_[idx]))\n",
        "          self.b -= self.lr * y_[idx]\n",
        "  \n",
        "  def predict(self, X):\n",
        "    linear_output = np.dot(X, self.w) - self.b\n",
        "    return(np.sign(linear_output))\n",
        "\n",
        "X, y =  datasets.make_blobs(n_samples=50, n_features=3, centers=3, cluster_std=1.05, random_state=40)\n",
        "y = np.where(y == 0, -1, 1)\n",
        "\n",
        "clf = SVM()\n",
        "clf.fit(X, y)\n",
        "predictions = clf.predict(X)\n",
        " \n",
        "print(clf.w, clf.b)\n",
        "\n",
        "def visualize_svm():\n",
        "     def get_hyperplane_value(x, w, b, offset):\n",
        "          return (-w[0] * x + b + offset) / w[1]\n",
        "\n",
        "     fig = plt.figure()\n",
        "     ax = fig.add_subplot(1,1,1)\n",
        "     plt.scatter(X[:,0], X[:,1], marker='o',c=y)\n",
        "\n",
        "     x0_1 = np.amin(X[:,0])\n",
        "     x0_2 = np.amax(X[:,0])\n",
        "\n",
        "     x1_1 = get_hyperplane_value(x0_1, clf.w, clf.b, 0)\n",
        "     x1_2 = get_hyperplane_value(x0_2, clf.w, clf.b, 0)\n",
        "\n",
        "     x1_1_m = get_hyperplane_value(x0_1, clf.w, clf.b, -1)\n",
        "     x1_2_m = get_hyperplane_value(x0_2, clf.w, clf.b, -1)\n",
        "\n",
        "     x1_1_p = get_hyperplane_value(x0_1, clf.w, clf.b, 1)\n",
        "     x1_2_p = get_hyperplane_value(x0_2, clf.w, clf.b, 1)\n",
        "\n",
        "     ax.plot([x0_1, x0_2],[x1_1, x1_2], 'y--')\n",
        "     ax.plot([x0_1, x0_2],[x1_1_m, x1_2_m], 'k')\n",
        "     ax.plot([x0_1, x0_2],[x1_1_p, x1_2_p], 'k')\n",
        "\n",
        "     x1_min = np.amin(X[:,1])\n",
        "     x1_max = np.amax(X[:,1])\n",
        "     ax.set_ylim([x1_min-3,x1_max+3])\n",
        "\n",
        "     plt.show()\n",
        "\n",
        "visualize_svm()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}